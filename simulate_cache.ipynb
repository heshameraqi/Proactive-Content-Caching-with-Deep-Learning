{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simulate_cache.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhpvrmO6AXKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0395f1ab-cfcf-4a60-f9a6-ff2cd3839577"
      },
      "source": [
        "%cd /content\n",
        "%rm -r ./Federated-Deep-Learning-for-Predictive-Content-Caching\n",
        "!git clone https://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@github.com/heshameraqi/Federated-Deep-Learning-for-Predictive-Content-Caching.git\n",
        "%cd Federated-Deep-Learning-for-Predictive-Content-Caching\n",
        "\n",
        "import logging, os\n",
        "logging.disable(logging.WARNING)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from data import MovieLensData\n",
        "import math\n",
        "import keras\n",
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from CFModel import CFModel, NCFModel  # Import Collaborative Filtering model architecture\n",
        "from math import floor\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "rm: cannot remove './Federated-Deep-Learning-for-Predictive-Content-Caching': No such file or directory\n",
            "Cloning into 'Federated-Deep-Learning-for-Predictive-Content-Caching'...\n",
            "remote: Enumerating objects: 303, done.\u001b[K\n",
            "remote: Counting objects: 100% (303/303), done.\u001b[K\n",
            "remote: Compressing objects: 100% (240/240), done.\u001b[K\n",
            "remote: Total 303 (delta 183), reused 111 (delta 57), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (303/303), 13.87 MiB | 7.75 MiB/s, done.\n",
            "Resolving deltas: 100% (183/183), done.\n",
            "/content/Federated-Deep-Learning-for-Predictive-Content-Caching\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-jRp3LXV0Oy"
      },
      "source": [
        "class ModelValidation:\n",
        "    def __init__(self, K_factor):\n",
        "        self.K_factor = K_factor # The number of dimensional embeddings for movies and users in the CF deep learning model\n",
        "        self.data = MovieLensData()\n",
        "        # Load data and print statistics\n",
        "        self.data.print_statistics()\n",
        "        # self.data.remove_movie_gap()  # TODO: uncomment this\n",
        "        self.users = self.data.ratings['user_emb_id'].values\n",
        "        self.movies = self.data.ratings['movie_emb_id'].values\n",
        "        # self.movies = [1,2,1,2,1,2,1,2]\n",
        "        # self.movies = [1,2,1,2,3,4,3,4]\n",
        "        self.ratings = self.data.ratings['rating'].values\n",
        "        # print(\"self.data.max_userid: \", self.data.max_userid, \" / self.data.max_movieid: \", self.data.max_movieid)\n",
        "\n",
        "    def train_ncf_model(self, nb_step, max_epochs=500, learning_rate=0.0001, cf_flag=False):\n",
        "        par_users = self.users\n",
        "        par_movies = self.movies\n",
        "        par_ratings = self.ratings\n",
        "        if cf_flag:\n",
        "            model = CFModel(self.data.max_userid, self.data.max_movieid, K_FACTORS).model\n",
        "        else:\n",
        "            model = NCFModel(self.data.max_userid, self.data.max_movieid, K_FACTORS).model\n",
        "        opt = keras.optimizers.Adamax(learning_rate=learning_rate)\n",
        "        model.compile(loss='mse', optimizer=opt)\n",
        "        # Callbacks monitor the validation loss, save the model weights each time the validation loss has improved\n",
        "        callbacks = [EarlyStopping('val_loss', patience=10), ModelCheckpoint(f'weights_full.h5', save_best_only=True)]\n",
        "        # Train the model: Use 60 epochs, 90% training data, 10% validation data\n",
        "        inputs = np.transpose(np.vstack((par_users, par_movies)))\n",
        "        history = model.fit(inputs, par_ratings, epochs=max_epochs, validation_split=.1, shuffle=True, batch_size=500, verbose=2, callbacks=callbacks)\n",
        "        # Plot training and validation RMSE\n",
        "        # loss = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ], 'training': [ math.sqrt(loss) for loss in history.history['loss'] ], 'validation': [ math.sqrt(loss) for loss in history.history['val_loss'] ]})\n",
        "        # ax = loss.ix[:,:].plot(x='epoch', figsize={7,10}, grid=True)\n",
        "        # ax.set_ylabel(\"root mean squared error\")\n",
        "        # ax.set_ylim([0.0,3.0]);\n",
        "        # Show the best validation RMSE\n",
        "        min_val_loss, idx = min((val, idx) for (idx, val) in enumerate(history.history['val_loss']))\n",
        "        print('Minimum RMSE at epoch', '{:d}'.format(idx + 1), '=', '{:.4f}'.format(math.sqrt(min_val_loss)))\n",
        "\n",
        "    def apply_ncf_model(self, weights_file, cf_flag=False):\n",
        "        # the default model will be ncf, cf will be used instead only if specified\n",
        "        if cf_flag:\n",
        "            trained_model = CFModel(self.data.max_userid, self.data.max_movieid, K_FACTORS)\n",
        "            # Load weights\n",
        "            trained_model.model.load_weights(weights_file)\n",
        "        else:\n",
        "            trained_model = NCFModel(self.data.max_userid, self.data.max_movieid, K_FACTORS)\n",
        "            trained_model.model.load_weights(weights_file)\n",
        "        # rec_movies_list_all = list()\n",
        "        # If a movie is recommended for more than X (threshold) users, it will be cached\n",
        "        # For every user TODO: should be every user in the past stages only not future\n",
        "        # TODO: Batch the data to the modetrain_ncf_modell\n",
        "        for i in range(len(self.users)):\n",
        "            # Predict user i ratings (enter user and his recommended movies --> get rating)\n",
        "            user_ratings = self.data.ratings[self.data.ratings['user_emb_id'] == i][['user_emb_id', 'movie_emb_id', 'rating']]\n",
        "            user_ratings['prediction'] = user_ratings.apply(lambda x: trained_model.rate(i, x['movie_emb_id']), axis=1)\n",
        "            user_ratings = user_ratings.sort_values(by='rating', ascending=False).merge(self.data.movies, on='movie_emb_id', how='inner', suffixes=['_u', '_m']).head(20)\n",
        "            # print(user_ratings)\n",
        "            print(user_ratings['rating'])\n",
        "            print(user_ratings['prediction'])\n",
        "\n",
        "            # Recommend user items (enter user and all movies --> get rating and sort them by best)\n",
        "            # Remove from data.ratings the movies already rated/requested by the user and predict from the list of movies not yet rated\n",
        "            # user_ratings = self.data.ratings[self.data.ratings['user_emb_id'] == i][['user_emb_id', 'movie_emb_id', 'rating']]\n",
        "            # recommendations = self.data.ratings[self.data.ratings['movie_emb_id'].isin(user_ratings['movie_emb_id']) == False][['movie_emb_id']].drop_duplicates()\n",
        "            # recommendations['prediction'] = recommendations.apply(lambda x: trained_model.rate(i, x['movie_emb_id']), axis=1)\n",
        "            # recommendations = recommendations.sort_values(by='prediction', ascending=False).merge(self.data.movies, on='movie_emb_id', how='inner', suffixes=['_u', '_m']).head(20)\n",
        "            # print(recommendations)\n",
        "            # rec_movies_list_user = recommendations[\"movie_emb_id\"].tolist()\n",
        "            # rec_movies_list_all.append(rec_movies_list_user)\n",
        "        # return rec_movies_list_all"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMOryWanZ29F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a42f1132-3cfb-48fb-e910-8a4235222321"
      },
      "source": [
        "# Configurations\n",
        "# test_ratio = 0.1\n",
        "# batch_size = 256\n",
        "# split_mode = 'seq-aware'  # seq-aware or random\n",
        "# feedback = 'explicit'  # explicit or implicit\n",
        "K_FACTORS = 100\n",
        "nb_step = 4\n",
        "# cache_size = 10\n",
        "model_val = ModelValidation(K_FACTORS)\n",
        "# print(CFModel(model_val.data.max_userid, model_val.data.max_movieid, K_FACTORS).model.summary())\n",
        "model_val.train_ncf_model(nb_step, max_epochs=500, learning_rate=0.0001)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         user_id  movie_id  rating  timestamp  user_emb_id  movie_emb_id\n",
            "1000138     6040       848       4  956703932         6039           847\n",
            "1000153     6040      2316       4  956703954         6039          2315\n",
            "999873      6040       590       5  956703954         6039           589\n",
            "1000007     6040      1893       4  956703977         6039          1892\n",
            "1000192     6040      1951       5  956703977         6039          1950\n",
            "number of users: 6040, number of movies: 3706\n",
            "number of ratings: 1000209, num_users*num_movies: 22384240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1801/1801 - 13s - loss: 6.7061 - val_loss: 1.7159\n",
            "Epoch 2/500\n",
            "1801/1801 - 10s - loss: 1.6908 - val_loss: 1.1418\n",
            "Epoch 3/500\n",
            "1801/1801 - 10s - loss: 1.3414 - val_loss: 1.0708\n",
            "Epoch 4/500\n",
            "1801/1801 - 10s - loss: 1.2396 - val_loss: 1.0309\n",
            "Epoch 5/500\n",
            "1801/1801 - 10s - loss: 1.1781 - val_loss: 1.0021\n",
            "Epoch 6/500\n",
            "1801/1801 - 10s - loss: 1.1334 - val_loss: 0.9792\n",
            "Epoch 7/500\n",
            "1801/1801 - 10s - loss: 1.0943 - val_loss: 0.9607\n",
            "Epoch 8/500\n",
            "1801/1801 - 10s - loss: 1.0677 - val_loss: 0.9467\n",
            "Epoch 9/500\n",
            "1801/1801 - 10s - loss: 1.0441 - val_loss: 0.9331\n",
            "Epoch 10/500\n",
            "1801/1801 - 10s - loss: 1.0213 - val_loss: 0.9246\n",
            "Epoch 11/500\n",
            "1801/1801 - 10s - loss: 1.0057 - val_loss: 0.9177\n",
            "Epoch 12/500\n",
            "1801/1801 - 10s - loss: 0.9904 - val_loss: 0.9096\n",
            "Epoch 13/500\n",
            "1801/1801 - 10s - loss: 0.9755 - val_loss: 0.9048\n",
            "Epoch 14/500\n",
            "1801/1801 - 10s - loss: 0.9623 - val_loss: 0.8996\n",
            "Epoch 15/500\n",
            "1801/1801 - 10s - loss: 0.9515 - val_loss: 0.8958\n",
            "Epoch 16/500\n",
            "1801/1801 - 10s - loss: 0.9409 - val_loss: 0.8912\n",
            "Epoch 17/500\n",
            "1801/1801 - 10s - loss: 0.9308 - val_loss: 0.8871\n",
            "Epoch 18/500\n",
            "1801/1801 - 10s - loss: 0.9222 - val_loss: 0.8844\n",
            "Epoch 19/500\n",
            "1801/1801 - 10s - loss: 0.9128 - val_loss: 0.8817\n",
            "Epoch 20/500\n",
            "1801/1801 - 10s - loss: 0.9056 - val_loss: 0.8787\n",
            "Epoch 21/500\n",
            "1801/1801 - 10s - loss: 0.8978 - val_loss: 0.8751\n",
            "Epoch 22/500\n",
            "1801/1801 - 10s - loss: 0.8897 - val_loss: 0.8755\n",
            "Epoch 23/500\n",
            "1801/1801 - 10s - loss: 0.8815 - val_loss: 0.8734\n",
            "Epoch 24/500\n",
            "1801/1801 - 10s - loss: 0.8743 - val_loss: 0.8699\n",
            "Epoch 25/500\n",
            "1801/1801 - 10s - loss: 0.8681 - val_loss: 0.8686\n",
            "Epoch 26/500\n",
            "1801/1801 - 10s - loss: 0.8610 - val_loss: 0.8665\n",
            "Epoch 27/500\n",
            "1801/1801 - 10s - loss: 0.8543 - val_loss: 0.8663\n",
            "Epoch 28/500\n",
            "1801/1801 - 10s - loss: 0.8475 - val_loss: 0.8628\n",
            "Epoch 29/500\n",
            "1801/1801 - 10s - loss: 0.8403 - val_loss: 0.8627\n",
            "Epoch 30/500\n",
            "1801/1801 - 10s - loss: 0.8335 - val_loss: 0.8609\n",
            "Epoch 31/500\n",
            "1801/1801 - 10s - loss: 0.8272 - val_loss: 0.8589\n",
            "Epoch 32/500\n",
            "1801/1801 - 10s - loss: 0.8208 - val_loss: 0.8583\n",
            "Epoch 33/500\n",
            "1801/1801 - 10s - loss: 0.8138 - val_loss: 0.8564\n",
            "Epoch 34/500\n",
            "1801/1801 - 10s - loss: 0.8069 - val_loss: 0.8555\n",
            "Epoch 35/500\n",
            "1801/1801 - 10s - loss: 0.8016 - val_loss: 0.8538\n",
            "Epoch 36/500\n",
            "1801/1801 - 10s - loss: 0.7942 - val_loss: 0.8527\n",
            "Epoch 37/500\n",
            "1801/1801 - 10s - loss: 0.7881 - val_loss: 0.8514\n",
            "Epoch 38/500\n",
            "1801/1801 - 10s - loss: 0.7809 - val_loss: 0.8506\n",
            "Epoch 39/500\n",
            "1801/1801 - 10s - loss: 0.7742 - val_loss: 0.8495\n",
            "Epoch 40/500\n",
            "1801/1801 - 10s - loss: 0.7675 - val_loss: 0.8487\n",
            "Epoch 41/500\n",
            "1801/1801 - 10s - loss: 0.7605 - val_loss: 0.8474\n",
            "Epoch 42/500\n",
            "1801/1801 - 10s - loss: 0.7542 - val_loss: 0.8475\n",
            "Epoch 43/500\n",
            "1801/1801 - 10s - loss: 0.7483 - val_loss: 0.8455\n",
            "Epoch 44/500\n",
            "1801/1801 - 10s - loss: 0.7418 - val_loss: 0.8465\n",
            "Epoch 45/500\n",
            "1801/1801 - 10s - loss: 0.7343 - val_loss: 0.8456\n",
            "Epoch 46/500\n",
            "1801/1801 - 10s - loss: 0.7286 - val_loss: 0.8453\n",
            "Epoch 47/500\n",
            "1801/1801 - 10s - loss: 0.7220 - val_loss: 0.8429\n",
            "Epoch 48/500\n",
            "1801/1801 - 10s - loss: 0.7159 - val_loss: 0.8432\n",
            "Epoch 49/500\n",
            "1801/1801 - 10s - loss: 0.7094 - val_loss: 0.8434\n",
            "Epoch 50/500\n",
            "1801/1801 - 10s - loss: 0.7035 - val_loss: 0.8421\n",
            "Epoch 51/500\n",
            "1801/1801 - 10s - loss: 0.6964 - val_loss: 0.8425\n",
            "Epoch 52/500\n",
            "1801/1801 - 10s - loss: 0.6906 - val_loss: 0.8415\n",
            "Epoch 53/500\n",
            "1801/1801 - 10s - loss: 0.6850 - val_loss: 0.8405\n",
            "Epoch 54/500\n",
            "1801/1801 - 10s - loss: 0.6778 - val_loss: 0.8408\n",
            "Epoch 55/500\n",
            "1801/1801 - 10s - loss: 0.6726 - val_loss: 0.8401\n",
            "Epoch 56/500\n",
            "1801/1801 - 10s - loss: 0.6665 - val_loss: 0.8407\n",
            "Epoch 57/500\n",
            "1801/1801 - 10s - loss: 0.6609 - val_loss: 0.8392\n",
            "Epoch 58/500\n",
            "1801/1801 - 10s - loss: 0.6541 - val_loss: 0.8407\n",
            "Epoch 59/500\n",
            "1801/1801 - 10s - loss: 0.6488 - val_loss: 0.8401\n",
            "Epoch 60/500\n",
            "1801/1801 - 10s - loss: 0.6429 - val_loss: 0.8412\n",
            "Epoch 61/500\n",
            "1801/1801 - 10s - loss: 0.6371 - val_loss: 0.8404\n",
            "Epoch 62/500\n",
            "1801/1801 - 10s - loss: 0.6314 - val_loss: 0.8409\n",
            "Epoch 63/500\n",
            "1801/1801 - 10s - loss: 0.6255 - val_loss: 0.8404\n",
            "Epoch 64/500\n",
            "1801/1801 - 10s - loss: 0.6202 - val_loss: 0.8411\n",
            "Epoch 65/500\n",
            "1801/1801 - 10s - loss: 0.6146 - val_loss: 0.8419\n",
            "Epoch 66/500\n",
            "1801/1801 - 10s - loss: 0.6090 - val_loss: 0.8425\n",
            "Epoch 67/500\n",
            "1801/1801 - 10s - loss: 0.6037 - val_loss: 0.8436\n",
            "Minimum RMSE at epoch 57 = 0.9161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVu1x0zeY0Ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d14a593-e823-4f73-82d3-61d6fabc339e"
      },
      "source": [
        "trained_model = NCFModel(model_val.data.max_userid, model_val.data.max_movieid, K_FACTORS) # NCFModel or CFModel\n",
        "trained_model.model.load_weights(f'weights_full.h5')\n",
        "\n",
        "i = 2\n",
        "user_ratings = model_val.data.ratings[model_val.data.ratings['user_emb_id'] == i][['user_emb_id', 'movie_emb_id', 'rating']]\n",
        "user_ratings['prediction'] = user_ratings.apply(lambda x: trained_model.rate(i, x['movie_emb_id']), axis=1)\n",
        "# user_ratings = user_ratings.sort_values(by='rating', ascending=False).merge(model_val.data.movies, on='movie_emb_id', how='inner', suffixes=['_u', '_m']).head(20)\n",
        "print(user_ratings['rating'])\n",
        "print(user_ratings['prediction'])\n",
        "\n",
        "# rec_movies_list_all = model_val.apply_ncf_model(f'weights_full.h5')  # contains the recommended movies for each user\n",
        "# flat_rec_list = list(dict.fromkeys([item for sublist in rec_movies_list_all for item in sublist]))  # flat list of recommended movies\n",
        "# print(rec_movies_list_all)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "217    3\n",
            "202    4\n",
            "186    3\n",
            "230    4\n",
            "225    4\n",
            "190    3\n",
            "209    5\n",
            "226    5\n",
            "218    4\n",
            "216    5\n",
            "212    4\n",
            "201    5\n",
            "228    4\n",
            "211    4\n",
            "223    4\n",
            "214    5\n",
            "215    5\n",
            "195    4\n",
            "189    4\n",
            "198    5\n",
            "205    1\n",
            "199    3\n",
            "207    4\n",
            "194    5\n",
            "197    4\n",
            "227    4\n",
            "210    5\n",
            "229    4\n",
            "222    4\n",
            "204    4\n",
            "224    2\n",
            "206    4\n",
            "184    3\n",
            "188    4\n",
            "231    5\n",
            "203    3\n",
            "193    3\n",
            "185    4\n",
            "182    4\n",
            "220    5\n",
            "200    2\n",
            "221    3\n",
            "192    5\n",
            "196    5\n",
            "208    2\n",
            "213    5\n",
            "183    2\n",
            "219    5\n",
            "187    4\n",
            "191    3\n",
            "232    4\n",
            "Name: rating, dtype: int64\n",
            "217    4.133700\n",
            "202    4.367348\n",
            "186    3.207211\n",
            "230    3.827557\n",
            "225    3.803790\n",
            "190    2.946049\n",
            "209    3.867531\n",
            "226    3.672093\n",
            "218    3.029665\n",
            "216    3.169139\n",
            "212    3.692998\n",
            "201    3.904111\n",
            "228    3.738657\n",
            "211    4.075872\n",
            "223    3.654671\n",
            "214    4.158781\n",
            "215    4.146440\n",
            "195    3.712841\n",
            "189    3.540453\n",
            "198    3.468612\n",
            "205    3.510744\n",
            "199    3.575863\n",
            "207    3.263352\n",
            "194    3.525243\n",
            "197    3.051552\n",
            "227    3.164862\n",
            "210    3.650120\n",
            "229    3.198741\n",
            "222    3.232124\n",
            "204    3.252899\n",
            "224    3.185867\n",
            "206    3.123111\n",
            "184    3.199544\n",
            "188    3.048542\n",
            "231    4.094548\n",
            "203    4.018828\n",
            "193    3.981991\n",
            "185    3.854753\n",
            "182    3.797217\n",
            "220    3.798300\n",
            "200    3.244503\n",
            "221    3.795470\n",
            "192    3.606108\n",
            "196    4.058597\n",
            "208    3.792934\n",
            "213    3.619363\n",
            "183    3.466877\n",
            "219    3.387079\n",
            "187    3.362323\n",
            "191    3.368243\n",
            "232    3.782053\n",
            "Name: prediction, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZMKKorR2gim"
      },
      "source": [
        "class SimModel:\n",
        "    def __init__(self, K_factor):\n",
        "        self.K_factor = K_factor # The number of dimensional embeddings for movies and users in the CF deep learning model\n",
        "        self.data = MovieLensData()\n",
        "        # Load data and print statistics\n",
        "        self.data.print_statistics()\n",
        "        # self.data.remove_movie_gap()  # TODO: uncomment this\n",
        "        self.users = self.data.ratings['user_emb_id'].values\n",
        "        self.movies = self.data.ratings['movie_emb_id'].values\n",
        "        # self.movies = [1,2,1,2,1,2,1,2]\n",
        "        # self.movies = [1,2,1,2,3,4,3,4]\n",
        "        self.ratings = self.data.ratings['rating'].values\n",
        "        # print(\"self.data.max_userid: \", self.data.max_userid, \" / self.data.max_movieid: \", self.data.max_movieid)\n",
        "\n",
        "    def train_ncf_model(self, nb_step, cf_flag=False):\n",
        "        # the default model will be ncf, cf will be used instead only if specified\n",
        "        len_step = floor(len(self.movies)/nb_step)\n",
        "        # we cut the ratings file into multiple intervals where the model will be trained in one interval and used in the next one\n",
        "        for i in range(0, nb_step):\n",
        "            print(\"=============== Training stage %d ===============\"%(i))\n",
        "            inf_index = len_step * i\n",
        "            # inf_index = 0  # in case we want to create intervals by going back each time to the beginning of the file\n",
        "            if i == (nb_step-1):\n",
        "                sup_index = len(self.movies)  # in case some ratings were left when the file was divided into multiple intervals\n",
        "            else:\n",
        "                sup_index = len_step * (i+1)\n",
        "            par_users = self.users[inf_index:sup_index]\n",
        "            par_movies = self.movies[inf_index:sup_index]\n",
        "            par_ratings = self.ratings[inf_index:sup_index]\n",
        "            if cf_flag:\n",
        "                model = CFModel(self.data.max_userid, self.data.max_movieid, K_FACTORS).model\n",
        "            else:\n",
        "                model = NCFModel(self.data.max_userid, self.data.max_movieid, K_FACTORS).model\n",
        "            model.compile(loss='mse', optimizer='adamax')\n",
        "            # Callbacks monitor the validation loss, save the model weights each time the validation loss has improved\n",
        "            callbacks = [EarlyStopping('val_loss', patience=10), ModelCheckpoint(f'weights{i+1}.h5', save_best_only=True)]\n",
        "            # Train the model: Use 30 epochs, 90% training data, 10% validation data\n",
        "            inputs = np.transpose(np.vstack((par_users, par_movies)))\n",
        "            history = model.fit(inputs, par_ratings, epochs=60, validation_split=.1, shuffle=True, batch_size=500, verbose=2, callbacks=callbacks)\n",
        "            # Plot training and validation RMSE\n",
        "            # loss = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ], 'training': [ math.sqrt(loss) for loss in history.history['loss'] ], 'validation': [ math.sqrt(loss) for loss in history.history['val_loss'] ]})\n",
        "            # ax = loss.ix[:,:].plot(x='epoch', figsize={7,10}, grid=True)\n",
        "            # ax.set_ylabel(\"root mean squared error\")\n",
        "            # ax.set_ylim([0.0,3.0]);\n",
        "            # Show the best validation RMSE\n",
        "            min_val_loss, idx = min((val, idx) for (idx, val) in enumerate(history.history['val_loss']))\n",
        "            print('Minimum RMSE at epoch', '{:d}'.format(idx + 1), '=', '{:.4f}'.format(math.sqrt(min_val_loss)))\n",
        "\n",
        "    def apply_ncf_model(self, weights_file, cf_flag=False):\n",
        "        # the default model will be ncf, cf will be used instead only if specified\n",
        "        if cf_flag:\n",
        "            trained_model = CFModel(self.data.max_userid, self.data.max_movieid, K_FACTORS)\n",
        "            # Load weights\n",
        "            trained_model.model.load_weights(weights_file)\n",
        "        else:\n",
        "            trained_model = NCFModel(self.data.max_userid, self.data.max_movieid, K_FACTORS)\n",
        "            trained_model.model.load_weights(weights_file)\n",
        "        rec_movies_list_all = list()\n",
        "        # If a movie is recommended for more than X (threshold) users, it will be cached\n",
        "        # For every user TODO: should be every user in the past stages only not future\n",
        "        # TODO: Batch the data to the model\n",
        "        for i in range(len(self.users)):\n",
        "            # Predict user i ratings (enter user and his recommended movies --> get rating)\n",
        "            # print(\"data.ratings: \\n\", data.ratings)\n",
        "            user_ratings = self.data.ratings[self.data.ratings['user_emb_id'] == i][['user_emb_id', 'movie_id', 'rating']]\n",
        "            user_ratings['prediction'] = user_ratings.apply(lambda x: trained_model.rate(i, x['movie_id']), axis=1)\n",
        "            user_ratings = user_ratings.sort_values(by='rating', ascending=False).merge(self.data.movies, on='movie_id', how='inner', suffixes=['_u', '_m']).head(20)\n",
        "            print(user_ratings)\n",
        "            # Recommend user items (enter user and all movies --> get rating and sort them by best)\n",
        "            # Remove from data.ratings the movies already rated/requested by the user and predict from the list of movies not yet rated\n",
        "            # user_ratings = self.data.ratings[self.data.ratings['user_id'] == i][['user_id', 'movie_id', 'rating']]\n",
        "            # recommendations = self.data.ratings[self.data.ratings['movie_id'].isin(user_ratings['movie_id']) == False][['movie_id']].drop_duplicates()\n",
        "            # recommendations['prediction'] = recommendations.apply(lambda x: trained_model.rate(i, x['movie_id']), axis=1)\n",
        "            # recommendations = recommendations.sort_values(by='prediction', ascending=False).merge(self.data.movies, on='movie_id', how='inner', suffixes=['_u', '_m']).head(20)\n",
        "            # print(recommendations)\n",
        "            # rec_movies_list_user = recommendations[\"movie_id\"].tolist()\n",
        "            # rec_movies_list_all.append(rec_movies_list_user)\n",
        "            # print(recommended_movies_list)\n",
        "        # return rec_movies_list_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI0Bnm7yaZfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99cfd6e6-3278-4a48-e345-94021eea6e03"
      },
      "source": [
        "# Configurations\n",
        "# test_ratio = 0.1\n",
        "# batch_size = 256\n",
        "# split_mode = 'seq-aware'  # seq-aware or random\n",
        "# feedback = 'explicit'  # explicit or implicit\n",
        "K_FACTORS = 100\n",
        "nb_step = 4\n",
        "# cache_size = 10\n",
        "sim_model = SimModel(K_FACTORS)\n",
        "sim_model.train_ncf_model(nb_step)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   user_id  movie_id  rating  timestamp  user_emb_id  movie_emb_id\n",
            "0        1      1193       5  978300760            0          1192\n",
            "1        1       661       3  978302109            0           660\n",
            "2        1       914       3  978301968            0           913\n",
            "3        1      3408       4  978300275            0          3407\n",
            "4        1      2355       5  978824291            0          2354\n",
            "number of users: 6040, number of movies: 3706\n",
            "number of ratings: 1000209, num_users*num_movies: 22384240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "=============== Training stage 0 ===============\n",
            "Epoch 1/60\n",
            "451/451 - 3s - loss: 3.4880 - val_loss: 1.4523\n",
            "Epoch 2/60\n",
            "451/451 - 2s - loss: 1.3742 - val_loss: 1.3094\n",
            "Epoch 3/60\n",
            "451/451 - 2s - loss: 1.3310 - val_loss: 1.2406\n",
            "Epoch 4/60\n",
            "451/451 - 2s - loss: 1.2951 - val_loss: 1.1449\n",
            "Epoch 5/60\n",
            "451/451 - 2s - loss: 1.2858 - val_loss: 1.1410\n",
            "Epoch 6/60\n",
            "451/451 - 2s - loss: 1.2673 - val_loss: 1.1434\n",
            "Epoch 7/60\n",
            "451/451 - 2s - loss: 1.2596 - val_loss: 1.0862\n",
            "Epoch 8/60\n",
            "451/451 - 2s - loss: 1.2443 - val_loss: 1.0880\n",
            "Epoch 9/60\n",
            "451/451 - 2s - loss: 1.2390 - val_loss: 1.0785\n",
            "Epoch 10/60\n",
            "451/451 - 2s - loss: 1.2338 - val_loss: 1.1035\n",
            "Epoch 11/60\n",
            "451/451 - 2s - loss: 1.2246 - val_loss: 1.0584\n",
            "Epoch 12/60\n",
            "451/451 - 2s - loss: 1.2138 - val_loss: 1.0740\n",
            "Epoch 13/60\n",
            "451/451 - 2s - loss: 1.2139 - val_loss: 1.0533\n",
            "Epoch 14/60\n",
            "451/451 - 2s - loss: 1.2081 - val_loss: 1.0488\n",
            "Epoch 15/60\n",
            "451/451 - 2s - loss: 1.2117 - val_loss: 1.0480\n",
            "Epoch 16/60\n",
            "451/451 - 2s - loss: 1.2091 - val_loss: 1.0434\n",
            "Epoch 17/60\n",
            "451/451 - 2s - loss: 1.2069 - val_loss: 1.0462\n",
            "Epoch 18/60\n",
            "451/451 - 2s - loss: 1.2038 - val_loss: 1.0224\n",
            "Epoch 19/60\n",
            "451/451 - 2s - loss: 1.1966 - val_loss: 1.0225\n",
            "Epoch 20/60\n",
            "451/451 - 2s - loss: 1.1988 - val_loss: 1.0349\n",
            "Epoch 21/60\n",
            "451/451 - 2s - loss: 1.2028 - val_loss: 1.0215\n",
            "Epoch 22/60\n",
            "451/451 - 2s - loss: 1.1987 - val_loss: 1.0094\n",
            "Epoch 23/60\n",
            "451/451 - 2s - loss: 1.1951 - val_loss: 1.0287\n",
            "Epoch 24/60\n",
            "451/451 - 2s - loss: 1.2005 - val_loss: 1.0037\n",
            "Epoch 25/60\n",
            "451/451 - 2s - loss: 1.1956 - val_loss: 1.0115\n",
            "Epoch 26/60\n",
            "451/451 - 2s - loss: 1.1952 - val_loss: 1.0371\n",
            "Epoch 27/60\n",
            "451/451 - 2s - loss: 1.1959 - val_loss: 1.0129\n",
            "Epoch 28/60\n",
            "451/451 - 2s - loss: 1.1936 - val_loss: 1.0018\n",
            "Epoch 29/60\n",
            "451/451 - 2s - loss: 1.1953 - val_loss: 1.0049\n",
            "Epoch 30/60\n",
            "451/451 - 2s - loss: 1.1947 - val_loss: 1.0120\n",
            "Epoch 31/60\n",
            "451/451 - 2s - loss: 1.1935 - val_loss: 1.0170\n",
            "Epoch 32/60\n",
            "451/451 - 2s - loss: 1.1900 - val_loss: 1.0130\n",
            "Epoch 33/60\n",
            "451/451 - 2s - loss: 1.1951 - val_loss: 1.0065\n",
            "Epoch 34/60\n",
            "451/451 - 2s - loss: 1.1884 - val_loss: 1.0045\n",
            "Epoch 35/60\n",
            "451/451 - 2s - loss: 1.1885 - val_loss: 1.0101\n",
            "Epoch 36/60\n",
            "451/451 - 2s - loss: 1.1885 - val_loss: 1.0026\n",
            "Epoch 37/60\n",
            "451/451 - 2s - loss: 1.1924 - val_loss: 1.0014\n",
            "Epoch 38/60\n",
            "451/451 - 2s - loss: 1.1894 - val_loss: 0.9918\n",
            "Epoch 39/60\n",
            "451/451 - 2s - loss: 1.1906 - val_loss: 0.9856\n",
            "Epoch 40/60\n",
            "451/451 - 2s - loss: 1.1897 - val_loss: 1.0069\n",
            "Epoch 41/60\n",
            "451/451 - 2s - loss: 1.1861 - val_loss: 0.9849\n",
            "Epoch 42/60\n",
            "451/451 - 2s - loss: 1.1903 - val_loss: 0.9890\n",
            "Epoch 43/60\n",
            "451/451 - 2s - loss: 1.1907 - val_loss: 0.9997\n",
            "Epoch 44/60\n",
            "451/451 - 2s - loss: 1.1820 - val_loss: 1.0001\n",
            "Epoch 45/60\n",
            "451/451 - 2s - loss: 1.1827 - val_loss: 1.0000\n",
            "Epoch 46/60\n",
            "451/451 - 2s - loss: 1.1851 - val_loss: 1.0004\n",
            "Epoch 47/60\n",
            "451/451 - 2s - loss: 1.1826 - val_loss: 0.9861\n",
            "Epoch 48/60\n",
            "451/451 - 2s - loss: 1.1798 - val_loss: 0.9989\n",
            "Epoch 49/60\n",
            "451/451 - 2s - loss: 1.1847 - val_loss: 0.9938\n",
            "Epoch 50/60\n",
            "451/451 - 2s - loss: 1.1821 - val_loss: 0.9989\n",
            "Epoch 51/60\n",
            "451/451 - 2s - loss: 1.1781 - val_loss: 0.9864\n",
            "Minimum RMSE at epoch 41 = 0.9924\n",
            "=============== Training stage 1 ===============\n",
            "Epoch 1/60\n",
            "451/451 - 3s - loss: 3.6504 - val_loss: 1.5468\n",
            "Epoch 2/60\n",
            "451/451 - 2s - loss: 1.3685 - val_loss: 1.4330\n",
            "Epoch 3/60\n",
            "451/451 - 2s - loss: 1.3188 - val_loss: 1.3828\n",
            "Epoch 4/60\n",
            "451/451 - 2s - loss: 1.2924 - val_loss: 1.3330\n",
            "Epoch 5/60\n",
            "451/451 - 2s - loss: 1.2682 - val_loss: 1.2305\n",
            "Epoch 6/60\n",
            "451/451 - 2s - loss: 1.2481 - val_loss: 1.2354\n",
            "Epoch 7/60\n",
            "451/451 - 2s - loss: 1.2428 - val_loss: 1.1863\n",
            "Epoch 8/60\n",
            "451/451 - 2s - loss: 1.2279 - val_loss: 1.2002\n",
            "Epoch 9/60\n",
            "451/451 - 2s - loss: 1.2156 - val_loss: 1.1469\n",
            "Epoch 10/60\n",
            "451/451 - 2s - loss: 1.2127 - val_loss: 1.1660\n",
            "Epoch 11/60\n",
            "451/451 - 2s - loss: 1.2066 - val_loss: 1.1507\n",
            "Epoch 12/60\n",
            "451/451 - 2s - loss: 1.2041 - val_loss: 1.1561\n",
            "Epoch 13/60\n",
            "451/451 - 2s - loss: 1.1983 - val_loss: 1.1384\n",
            "Epoch 14/60\n",
            "451/451 - 2s - loss: 1.1958 - val_loss: 1.0920\n",
            "Epoch 15/60\n",
            "451/451 - 2s - loss: 1.1994 - val_loss: 1.0993\n",
            "Epoch 16/60\n",
            "451/451 - 2s - loss: 1.1967 - val_loss: 1.1162\n",
            "Epoch 17/60\n",
            "451/451 - 2s - loss: 1.1930 - val_loss: 1.1086\n",
            "Epoch 18/60\n",
            "451/451 - 2s - loss: 1.1905 - val_loss: 1.0960\n",
            "Epoch 19/60\n",
            "451/451 - 2s - loss: 1.1936 - val_loss: 1.1000\n",
            "Epoch 20/60\n",
            "451/451 - 2s - loss: 1.1933 - val_loss: 1.0758\n",
            "Epoch 21/60\n",
            "451/451 - 2s - loss: 1.1932 - val_loss: 1.0890\n",
            "Epoch 22/60\n",
            "451/451 - 2s - loss: 1.1912 - val_loss: 1.0872\n",
            "Epoch 23/60\n",
            "451/451 - 2s - loss: 1.1828 - val_loss: 1.0530\n",
            "Epoch 24/60\n",
            "451/451 - 2s - loss: 1.1881 - val_loss: 1.0832\n",
            "Epoch 25/60\n",
            "451/451 - 2s - loss: 1.1863 - val_loss: 1.0534\n",
            "Epoch 26/60\n",
            "451/451 - 2s - loss: 1.1883 - val_loss: 1.0736\n",
            "Epoch 27/60\n",
            "451/451 - 2s - loss: 1.1878 - val_loss: 1.0402\n",
            "Epoch 28/60\n",
            "451/451 - 2s - loss: 1.1874 - val_loss: 1.0678\n",
            "Epoch 29/60\n",
            "451/451 - 2s - loss: 1.1833 - val_loss: 1.0618\n",
            "Epoch 30/60\n",
            "451/451 - 2s - loss: 1.1861 - val_loss: 1.0480\n",
            "Epoch 31/60\n",
            "451/451 - 2s - loss: 1.1829 - val_loss: 1.0381\n",
            "Epoch 32/60\n",
            "451/451 - 2s - loss: 1.1857 - val_loss: 1.0468\n",
            "Epoch 33/60\n",
            "451/451 - 2s - loss: 1.1891 - val_loss: 1.0404\n",
            "Epoch 34/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5ff037c5aabc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# cache_size = 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msim_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_FACTORS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msim_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ncf_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-f7d64fc11557>\u001b[0m in \u001b[0;36mtrain_ncf_model\u001b[0;34m(self, nb_step, cf_flag)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# Train the model: Use 30 epochs, 90% training data, 10% validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpar_movies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpar_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;31m# Plot training and validation RMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# loss = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ], 'training': [ math.sqrt(loss) for loss in history.history['loss'] ], 'validation': [ math.sqrt(loss) for loss in history.history['val_loss'] ]})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGi2nu29abLB"
      },
      "source": [
        "'''for i in range(0, nb_step):\n",
        "    print(\"=============== Testing stage %d ===============\"%(i))\n",
        "    rec_movies_list_all = sim_model.apply_ncf_model(f'weights{i + 1}.h5')  # contains the recommended movies for each user\n",
        "    flat_rec_list = list(dict.fromkeys([item for sublist in rec_movies_list_all for item in sublist]))  # flat list of recommended movies\n",
        "    # print(rec_movies_list_all)'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}