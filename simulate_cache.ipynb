{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RhpvrmO6AXKW",
    "outputId": "323f2417-4c6d-4b86-aae1-af7adb725a98"
   },
   "source": [
    "!git clone https://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@github.com/heshameraqi/Federated-Deep-Learning-for-Predictive-Content-Caching.git\n",
    "%cd Federated-Deep-Learning-for-Predictive-Content-Caching"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.1.0\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/1d/56/0dbdae2a3c527a119bec0d5cf441655fe030ce1daa6fa6b9542f7dbd8664/tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8MB)\n",
      "\u001B[K     |████████████████████████████████| 421.8MB 43kB/s \n",
      "\u001B[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.19.5)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
      "\u001B[K     |████████████████████████████████| 3.9MB 42.7MB/s \n",
      "\u001B[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Collecting keras-applications>=1.0.8\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001B[K     |████████████████████████████████| 51kB 5.5MB/s \n",
      "\u001B[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.36.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.34.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.12.4)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001B[K     |████████████████████████████████| 450kB 55.6MB/s \n",
      "\u001B[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (56.1.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.30.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.1.0) (1.5.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.4.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=2e409ba08b4be70250f8ee59700362d948b426a9521ec343caa205cddb8dd45d\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built gast\n",
      "\u001B[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001B[0m\n",
      "Installing collected packages: tensorboard, keras-applications, gast, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Found existing installation: tensorflow 2.5.0\n",
      "    Uninstalling tensorflow-2.5.0:\n",
      "      Successfully uninstalled tensorflow-2.5.0\n",
      "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "gast",
         "tensorboard",
         "tensorflow"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.1.5 in /usr/local/lib/python3.7/dist-packages (2.1.5)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (3.13)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.5) (1.15.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oTOOEYmhVP5x",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "outputId": "218adbc9-0201-42eb-e220-60e97ddf6b83"
   },
   "source": [
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from data import MovieLensData\n",
    "import math\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from CFModel import CFModel, NCFModel  # Import Collaborative Filtering model architecture\n",
    "from math import floor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SimModel:\n",
    "    def __init__(self, K_factor):\n",
    "        self.K_factor = K_factor # The number of dimensional embeddings for movies and users in the CF deep learning model\n",
    "        self.data = MovieLensData()\n",
    "        # Load data and print statistics\n",
    "        self.data.print_statistics()\n",
    "        self.data.remove_movie_gap()\n",
    "        self.users = self.data.ratings['user_emb_id'].values\n",
    "        self.movies = self.data.ratings['movie_emb_id'].values\n",
    "        # self.movies = [1,2,1,2,1,2,1,2]\n",
    "        # self.movies = [1,2,1,2,3,4,3,4]\n",
    "        self.ratings = self.data.ratings['rating'].values\n",
    "        # print(\"self.data.max_userid: \", self.data.max_userid, \" / self.data.max_movieid: \", self.data.max_movieid)\n",
    "\n",
    "    def train_ncf_model(self, nb_step, cf_flag=True):\n",
    "        # the default model will be ncf, cf will be used instead only if specified\n",
    "        len_step = floor(len(self.movies)/nb_step)\n",
    "        # we cut the ratings file into multiple intervals where the model will be trained in one interval and used in the next one\n",
    "        for i in range(0, nb_step):\n",
    "            inf_index = len_step * i\n",
    "            # inf_index = 0  # in case we want to create intervals by going back each time to the beginning of the file\n",
    "            if i == (nb_step-1):\n",
    "                sup_index = len(self.movies)  # in case some ratings were left when the file was divided into multiple intervals\n",
    "            else:\n",
    "                sup_index = len_step * (i+1)\n",
    "            par_users = self.users[inf_index:sup_index]\n",
    "            par_movies = self.movies[inf_index:sup_index]\n",
    "            par_ratings = self.ratings[inf_index:sup_index]\n",
    "            if cf_flag:\n",
    "                model = CFModel(self.data.max_userid, self.data.max_movieid, K_FACTORS)\n",
    "            else:\n",
    "                model_ncf = NCFModel(self.data.max_userid, self.data.max_movieid, K_FACTORS)\n",
    "                model = model_ncf.model_final\n",
    "            model.compile(loss='mse', optimizer='adamax')\n",
    "            # Callbacks monitor the validation loss, save the model weights each time the validation loss has improved\n",
    "            callbacks = [EarlyStopping('val_loss', patience=2), ModelCheckpoint(f'weights{i+1}.h5', save_best_only=True)]\n",
    "            # Train the model: Use 30 epochs, 90% training data, 10% validation data\n",
    "            inputs = np.transpose(np.vstack((par_users, par_movies)))\n",
    "            history = model.fit(inputs, par_ratings, nb_epoch=30, validation_split=.1, shuffle=True, batch_size=500, verbose=2, callbacks=callbacks)\n",
    "            # Plot training and validation RMSE\n",
    "            # loss = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ], 'training': [ math.sqrt(loss) for loss in history.history['loss'] ], 'validation': [ math.sqrt(loss) for loss in history.history['val_loss'] ]})\n",
    "            # ax = loss.ix[:,:].plot(x='epoch', figsize={7,10}, grid=True)\n",
    "            # ax.set_ylabel(\"root mean squared error\")\n",
    "            # ax.set_ylim([0.0,3.0]);\n",
    "            # Show the best validation RMSE\n",
    "            min_val_loss, idx = min((val, idx) for (idx, val) in enumerate(history.history['val_loss']))\n",
    "            print('Minimum RMSE at epoch', '{:d}'.format(idx + 1), '=', '{:.4f}'.format(math.sqrt(min_val_loss)))\n",
    "\n",
    "    @staticmethod\n",
    "    def predict_rating(trained_model, user_id, movie_id):\n",
    "        return trained_model.rate(user_id - 1, movie_id - 1)\n",
    "\n",
    "    def apply_ncf_model(self, weights_file, cf_flag=False):\n",
    "        # the default model will be ncf, cf will be used instead only if specified\n",
    "        if cf_flag:\n",
    "            trained_model = CFModel(self.data.max_userid, self.data.max_movieid, K_FACTORS)\n",
    "            # Load weights\n",
    "            trained_model.load_weights(weights_file)\n",
    "        else:\n",
    "            trained_model = NCFModel(self.data.max_userid, self.data.max_movieid, K_FACTORS)\n",
    "            trained_model.model_final.load_weights(weights_file)\n",
    "        rec_movies_list_all = list()\n",
    "        # Use the pre-trained model\n",
    "        for i in range(1, len(self.users)+1):\n",
    "        # TODO: check which users to use (e.g., if a movie is recommended for more than X (threshold) users, it will be cached)\n",
    "        # TODO: this will depend on the caching scheme\n",
    "        # for i in range(1, 2):\n",
    "            # Predict user ratings (enter user and his recommended movies --> get rating)\n",
    "            # print(\"data.ratings: \\n\", data.ratings)\n",
    "            user_ratings = self.data.ratings[self.data.ratings['user_id'] == i][['user_id', 'movie_id', 'rating']]\n",
    "            user_ratings['prediction'] = user_ratings.apply(lambda x: SimModel.predict_rating(trained_model, i, x['movie_id']), axis=1)\n",
    "            user_ratings = user_ratings.sort_values(by='rating', ascending=False).merge(self.data.movies, on='movie_id', how='inner', suffixes=['_u', '_m']).head(20)\n",
    "            # print(user_ratings)\n",
    "            # Recommend user items (enter user and all movies --> get rating and sort them by best)\n",
    "            # Remove from data.ratings the movies already rated/requested by the user and predict from the list of movies not yet rated\n",
    "            recommendations = self.data.ratings[self.data.ratings['movie_id'].isin(user_ratings['movie_id']) == False][['movie_id']].drop_duplicates()\n",
    "            recommendations['prediction'] = recommendations.apply(lambda x: SimModel.predict_rating(trained_model, i, x['movie_id']), axis=1)\n",
    "            recommendations = recommendations.sort_values(by='prediction', ascending=False).merge(self.data.movies, on='movie_id', how='inner', suffixes=['_u', '_m']).head(20)\n",
    "            # print(recommendations)\n",
    "            rec_movies_list_user = recommendations[\"movie_id\"].tolist()\n",
    "            rec_movies_list_all.append(rec_movies_list_user)\n",
    "            # print(recommended_movies_list)\n",
    "        return rec_movies_list_all\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configurations\n",
    "    # test_ratio = 0.1\n",
    "    # batch_size = 256\n",
    "    # split_mode = 'seq-aware'  # seq-aware or random\n",
    "    # feedback = 'explicit'  # explicit or implicit\n",
    "    K_FACTORS = 100\n",
    "    nb_step = 2\n",
    "    # cache_size = 10\n",
    "    sim_model = SimModel(K_FACTORS)\n",
    "    sim_model.train_ncf_model(nb_step)\n",
    "    for i in range(0, nb_step):\n",
    "        rec_movies_list_all = sim_model.apply_ncf_model(f'weights{i + 1}.h5')  # contains the recommended movies for each user\n",
    "        flat_rec_list = list(dict.fromkeys([item for sublist in rec_movies_list_all for item in sublist]))  # flat list of recommended movies\n",
    "        # print(rec_movies_list_all)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-78ac9fedbc18>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mMovieLensData\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmath\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallbacks\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mCallback\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mEarlyStopping\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mModelCheckpoint\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mCFModel\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mCFModel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mNCFModel\u001B[0m  \u001B[0;31m# Import Collaborative Filtering model architecture\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0m__future__\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mabsolute_import\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mactivations\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mapplications\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mnp_utils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mto_categorical\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mnp_utils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnormalize\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mmulti_gpu_utils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmulti_gpu_model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/multi_gpu_utils.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0m__future__\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mprint_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmerge\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mconcatenate\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mbackend\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mK\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcore\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLambda\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgeneric_utils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdeserialize_keras_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLayer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mInput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mInputLayer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# note: topology.Node is an internal class,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m# it isn't meant to be used by Keras users.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mtopology\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mInputSpec\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mtopology\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mInput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mtopology\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mInputLayer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/topology.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mbackend\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mK\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0minitializers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mio_utils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mask_to_proceed_with_overwrite\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer_utils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mprint_summary\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mprint_layer_summary\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[0;31m# from ALL_OBJECTS. We make no guarantees as to whether these objects will\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[0;31m# using their correct version.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 124\u001B[0;31m \u001B[0mpopulate_deserializable_objects\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    125\u001B[0m \u001B[0mglobals\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mLOCAL\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mALL_OBJECTS\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/initializers/__init__.py\u001B[0m in \u001B[0;36mpopulate_deserializable_objects\u001B[0;34m()\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[0mv2_objs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m     \u001B[0mbase_cls\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minitializers_v2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mInitializer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 82\u001B[0;31m     generic_utils.populate_dict_with_module_objects(\n\u001B[0m\u001B[1;32m     83\u001B[0m         \u001B[0mv2_objs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m         \u001B[0;34m[\u001B[0m\u001B[0minitializers_v2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'"
     ]
    }
   ]
  }
 ]
}